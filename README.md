## A simple tutorial on convolution network in Python

It has a stochastic gradient descent algorithm, that uses a convolution layer, a perceptron layer (fully connection layer), and a softmax output layer. 
The convolution layer includes sublayers of linear convolution, nonlinear activation, and max pooling. 
The network can be composed with more layers. 
Demo cases are given for MNIST and CIFAR-10.

The convolution layer uses 4-level for-loop for convolution and gradients computations. It can be further optimized, but probably not necessary as a simple tutorial.
