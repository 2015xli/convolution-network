{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "class Conv2D:\n",
    "                     \n",
    "    def __init__(self, n_in, n_out, kernel, \n",
    "                 padding=\"same\", stride=(1,1), W=None, b=None):\n",
    "        \n",
    "        self.n_in = n_in\n",
    "        self.n_out = n_out\n",
    "        assert kernel != None and len(kernel) == 2\n",
    "        self.kernel = kernel\n",
    "\n",
    "        assert padding == \"valid\" or padding == \"same\"\n",
    "        self.padding = padding \n",
    "        self.pads = None\n",
    "        self.stride = stride\n",
    "\n",
    "        if W is None:\n",
    "            k_h, k_w = kernel\n",
    "            size = n_out * n_in * k_h * k_w \n",
    "            weights = np.random.uniform(size=size).reshape(n_out, n_in, k_h, k_w)\n",
    "            scale = np.sqrt(2./size)\n",
    "            W = weights * scale       \n",
    "        if b is None:\n",
    "            b = np.zeros(n_out)\n",
    "       \n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.X = None\n",
    "        self.Y = None\n",
    "        self.X_shape = None\n",
    "        self.Y_shape = None\n",
    "        \n",
    "        self.g_W = None\n",
    "        self.g_b = None\n",
    "        self.g_X = None\n",
    "        self.g_Y = None\n",
    "        \n",
    "        return\n",
    "   \n",
    "    def _compute_shapes_and_pads(self):\n",
    "        X_shape = self.X.shape\n",
    "        x_h = X_shape[1]\n",
    "        x_w = X_shape[2]\n",
    "        \n",
    "        s_h = self.stride[0]\n",
    "        s_w = self.stride[1]\n",
    "        k_h = self.kernel[0]\n",
    "        k_w = self.kernel[1]\n",
    "        \n",
    "        if self.padding == \"valid\":\n",
    "            y_h = int(np.ceil((x_h - k_h + 1) / s_h))\n",
    "            y_w = int(np.ceil((x_w - k_w + 1) / s_w))\n",
    "            zeros_h, zeros_w = (0,0)\n",
    "        else: # \"same\"\n",
    "            y_h = int(np.ceil(x_h / s_h))\n",
    "            y_w = int(np.ceil(x_w / s_w))\n",
    "            \n",
    "            # (y-1): index of last number of y, (y-1)*s: mapped to index in x\n",
    "            # (y-1)*s+k: count of needed elements of x, like (y-1)*s+1 + k-1 \n",
    "            # (y-1)*s+k-x: count of extra elements from x, possibly negative when x is enough to cover\n",
    "            zeros_h = max((y_h - 1) * s_h + k_h - x_h, 0)\n",
    "            zeros_w = max((y_w - 1) * s_w + k_w - x_w, 0)\n",
    "\n",
    "        pad0 = zeros_h // 2\n",
    "        pad1 = zeros_h - pad0\n",
    "        pad2 = zeros_w // 2\n",
    "        pad3 = zeros_w - pad2\n",
    "        self.pads = (pad0, pad1, pad2, pad3)\n",
    "        \n",
    "        self.Y_shape = (self.n_out, y_h, y_w)\n",
    "        self.X_shape = (self.n_in, x_h+zeros_h, x_w+zeros_w) \n",
    "        \n",
    "        # padding X\n",
    "        if (np.array(self.pads) == 0).all():\n",
    "            return self.X\n",
    "\n",
    "        new_h = x_h + zeros_h\n",
    "        new_w = x_w + zeros_w\n",
    "\n",
    "        padded_X = np.zeros(shape=(self.n_in, new_h, new_w))\n",
    "        padded_X[:, pad0:-pad1, pad2:-pad3] = self.X\n",
    "        \n",
    "        return padded_X\n",
    "    \n",
    "    def forward(self, X):\n",
    "    \n",
    "        assert X.ndim == 3\n",
    "        assert (np.array(X[0].shape) > np.array(self.kernel)).all()\n",
    "\n",
    "        self.X = X\n",
    "        if self.X_shape is None:\n",
    "            self.X = self._compute_shapes_and_pads() \n",
    "        else:\n",
    "            assert X.shape == self.X_shape\n",
    "\n",
    "        Y = np.zeros(shape=self.Y_shape)\n",
    "                \n",
    "        y_h = self.Y_shape[1]\n",
    "        y_w = self.Y_shape[2]\n",
    "        k_h, k_w = self.kernel\n",
    "        s_h, s_w = self.stride\n",
    "\n",
    "        for i_Y in range(self.n_out):\n",
    "            for i_X in range(self.n_in):\n",
    "                k = self.W[i_Y,i_X]\n",
    "                x = self.X[i_X]\n",
    "                for i in range(y_h):\n",
    "                    for j in range(y_w):\n",
    "                        r = i * s_h\n",
    "                        c = j * s_w\n",
    "                        Y[i_Y, i, j] += (x[r:r+k_h, c:c+k_w] * k).sum()\n",
    "             \n",
    "            Y[i_Y] += self.b[i_Y]\n",
    "        \n",
    "        self.Y = Y\n",
    "        return Y\n",
    "    \n",
    "    def backward(self, g_Y):\n",
    "        \n",
    "        assert g_Y.shape == self.Y_shape\n",
    "        n_out, y_h, y_w = self.Y_shape\n",
    "\n",
    "        s_h, s_w = self.stride\n",
    "        k_h, k_w = self.kernel\n",
    "\n",
    "        self.g_Y = g_Y\n",
    "        g_W = np.zeros(shape=(n_out, self.n_in, k_h, k_w))\n",
    "        g_b = np.zeros(n_out)\n",
    "        \n",
    "\n",
    "        for i_Y in range(self.n_out):\n",
    "            g_y = self.g_Y[i_Y]\n",
    "            for i_X in range(self.n_in):\n",
    "                x = self.X[i_X]\n",
    "                for i_kh in range(k_h):\n",
    "                    for i_kw in range(k_w):\n",
    "                        hs = i_kh; he = hs + y_h * s_h\n",
    "                        ws = i_kw; we = ws + y_w * s_w\n",
    "                        g_W[i_Y,i_X,i_kh,i_kw] = (g_y * x[hs:he:s_h, ws:we:s_w]).sum()\n",
    "        \n",
    "            g_b[i_Y] = g_y.sum()\n",
    "\n",
    "        g_X = np.zeros(shape=self.X_shape)\n",
    "\n",
    "        for i_yh in range(y_h):\n",
    "            i_xh = i_yh * s_h\n",
    "            for i_yw in range(y_w):\n",
    "                i_xw = i_yw * s_w\n",
    "                for i_Y in range(self.n_out):\n",
    "                    g_X[:, i_xh:i_xh+k_h, i_xw:i_xw+k_w] += self.W[i_Y] * g_Y[i_Y, i_yh, i_yw]  \n",
    "            \n",
    "        self.g_Y = g_Y\n",
    "        self.g_W = g_W\n",
    "        self.g_b = g_b\n",
    "        self.g_X = g_X\n",
    "        \n",
    "        return g_X\n",
    "    \n",
    "    def update(self, g_Y, learning=0.1):\n",
    "        \n",
    "        self.W -= learning * self.g_W\n",
    "        self.b -= learning * self.g_b\n",
    "        \n",
    "            \n",
    "    def __str__(self):\n",
    "        \n",
    "        s = \"\\nX is:\" + (\"\" if self.X is None else str(self.X.shape))\n",
    "        s += \"\\n\" + str(self.X)\n",
    "        s += \"\\npadding is: \" + str(self.pads)\n",
    "        s += \"\\nY is:\" + (\"\" if self.Y is None else str(self.Y.shape))\n",
    "        s += \"\\n\" + str(self.Y)\n",
    "        s += \"\\nkernel is: \" + str(self.W.shape)\n",
    "        s += \"\\n\" + str(self.W)\n",
    "        s += \"\\nbias is: \" + str(self.b.shape)\n",
    "        s += \"\\n\" + str(self.b)\n",
    "        s += \"\\nstride is:\\n\" + str(self.stride)\n",
    "        \n",
    "        s += \"\\ng_Y is:\" + (\"\" if self.g_Y is None else str(self.g_Y.shape))\n",
    "        s += \"\\n\" + str(self.g_Y)\n",
    "        s += \"\\ng_W is:\" + (\"\" if self.g_W is None else str(self.g_W.shape))\n",
    "        s += \"\\n\" + str(self.g_W)\n",
    "        s += \"\\ng_b is:\" + (\"\" if self.g_b is None else str(self.g_b.shape))\n",
    "        s += \"\\n\" + str(self.g_b)\n",
    "        s += \"\\ng_X is:\" + (\"\" if self.g_X is None else str(self.g_X.shape))\n",
    "        s += \"\\n\" + str(self.g_X)\n",
    "        return s\n",
    "\n",
    "# when we set all the kernels, biases, g_Y as ones, the resulted g_X shows \n",
    "# how many times one input x element has been used in forwarding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, pool=\"MAX\"):\n",
    "        return\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return X\n",
    "    \n",
    "    def backward(self, X):\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "class ConvolutionLayer:\n",
    "    def __init__(self, conv, acti=None, pool=None): \n",
    "        if conv is None: raise ValueError(\"Convolution layer is not assigned.\")\n",
    "        self.conv = conv\n",
    "\n",
    "        if acti is not None:\n",
    "            self.acti = Activation(acti)\n",
    "            self.A = None\n",
    "        else:\n",
    "            self.acti = None\n",
    "\n",
    "        \n",
    "        self.pool = pool\n",
    "\n",
    "        self.X = None\n",
    "        self.Y = None\n",
    "        self.Y_shape = None\n",
    "        return\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        self.Y = self.conv.forward(X)\n",
    "        \n",
    "        if self.acti is not None:\n",
    "            self.A = self.acti.func(self.Y)\n",
    "            self.Y = self.A\n",
    "        if self.pool is not None:\n",
    "            self.Y = self.pool.forward(self.Y)\n",
    "        \n",
    "        if self.Y_shape is None:\n",
    "            self.Y_shape = self.Y.shape\n",
    "        else:\n",
    "            assert self.Y_shape == self.Y.shape\n",
    "        \n",
    "        return self.Y\n",
    "    \n",
    "    def backward(self, g_Y):\n",
    "        self.g_Y = g_Y\n",
    "    \n",
    "        if self.pool is not None:\n",
    "            g_Y = self.pool.backward(g_Y)\n",
    "        if self.acti is not None:\n",
    "            g_acti = self.acti.grad(self.A)\n",
    "            g_Y = g_acti * g_Y\n",
    "            \n",
    "        g_Y = self.conv.backward(g_Y)\n",
    "        return g_Y\n",
    "        \n",
    "    def update(self, learning):\n",
    "        self.conv.update(learning)\n",
    "        return \n",
    "    \n",
    "    def OutputToFC(self):\n",
    "        return self.Y.reshape(-1, 1)\n",
    "\n",
    "    def InputFromFC(self, g_Y):\n",
    "        return g_Y.reshape(self.Y_shape)\n",
    "    \n",
    "    def __str__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.type = \"CNN\"\n",
    "        self.learning = 1\n",
    "        \n",
    "        n_in = 1; n_out = 5; kernel = (5,5); stride = (2,2); padding=\"valid\"\n",
    "        c = Conv2D(n_in, n_out, kernel=kernel, padding=padding, stride=stride)\n",
    "        self.convlayer1 = ConvolutionLayer(c, acti=\"RELU\")\n",
    "\n",
    "        #n_in = 5; n_out = 50; kernel = (5,5); stride = (2,2); padding=\"valid\"\n",
    "        #c = Conv2D(n_in, n_out, kernel=kernel, padding=padding, stride=stride)\n",
    "        #self.convlayer2 = ConvolutionLayer(c, acti=None)\n",
    "        \n",
    "        #n_in = 50 * 4 * 4; n_out = 100\n",
    "        n_in = 5 * 12 * 12; n_out = 100\n",
    "        f = PercepLayer(n_in, n_out, acti=\"RELU\")\n",
    "        self.perceplayer = f\n",
    "        \n",
    "        n_in = 100; n_out = 10\n",
    "        f = SoftMaxLayer(n_in, n_out)\n",
    "        self.outlayer = f\n",
    "        return\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.convlayer1.forward(X)\n",
    "        #X = self.convlayer2.forward(X)\n",
    "        #X = self.convlayer2.OutputToFC()\n",
    "        X = self.convlayer1.OutputToFC()\n",
    "        X = self.perceplayer.forward(X)\n",
    "        return self.outlayer.forward(X)\n",
    "    \n",
    "    def backward(self, label):\n",
    "        g_Y = self.outlayer.backward(label)\n",
    "        g_Y = self.perceplayer.backward(g_Y)\n",
    "        g_Y = self.convlayer1.InputFromFC(g_Y)\n",
    "        #g_Y = self.convlayer2.InputFromFC(g_Y)\n",
    "        #g_Y = self.convlayer2.backward(g_Y)\n",
    "        g_Y = self.convlayer1.backward(g_Y)\n",
    "        return\n",
    "    \n",
    "    def update(self, learning):\n",
    "        self.outlayer.update(learning)\n",
    "        self.perceplayer.update(learning)\n",
    "        #self.convlayer2.update(learning)\n",
    "        self.convlayer1.update(learning)        \n",
    "        return\n",
    "    \n",
    "    def train_1sample(self, X, label):\n",
    "        self.forward(X)\n",
    "        self.backward(label)\n",
    "        self.update(self.learning)\n",
    "        return\n",
    " \n",
    "    def predict_1sample(self, X):\n",
    "        predict = self.forward(X)\n",
    "        return predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run 'multilayer-perceptron.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0 accuracy: 0.15\n"
     ]
    }
   ],
   "source": [
    "def run_cnn_test():\n",
    "    n_out = 2; n_in = 2; kernel = (2,3); stride = (1,3); padding=\"same\"\n",
    "    W = np.ones(shape=(n_out, n_in, kernel[0], kernel[1]))\n",
    "    bias = np.ones(n_out)\n",
    "\n",
    "    c = Conv2D(n_out, n_in, kernel=kernel, padding=padding, stride=stride, W=W, b=bias)\n",
    "    \n",
    "    l = ConvolutionLayer(c)\n",
    "    \n",
    "    a = np.ones(15).reshape(3,5)\n",
    "    b = np.array([a,a])\n",
    "    print(b)\n",
    "\n",
    "    l.forward(b)\n",
    "    print(c)\n",
    "\n",
    "#   g = np.ones(shape=c.Y_shape)\n",
    "    g = np.array([[[1,-1],[1,-1],[-1,-1]],[[1,1],[1,1],[1,-1]]])\n",
    "    print(g)\n",
    "    l.backward(g)\n",
    "    print(c)\n",
    "\n",
    "def run_cnn_mnist():\n",
    "    #set_trace()\n",
    "    cnn = CNN()\n",
    "    mnist = MNIST(cnn)\n",
    "    #for i in range(10):\n",
    "    mnist.train(10000)\n",
    "    accuracy = mnist.test(100)\n",
    "    print(\"\\nEpoch {} accuracy: {}\".format(0, accuracy))\n",
    "\n",
    "def is_main_module():\n",
    "    return __name__ == '__main__' and '__file__' not in globals()\n",
    "\n",
    "if is_main_module():\n",
    "    #run_cnn_test()\n",
    "    np.seterr(all='raise')\n",
    "    run_cnn_mnist()\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
